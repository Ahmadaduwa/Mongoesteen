{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e3f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec0e9338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- config ---\n",
    "DATA_DIR = \"./DataTrain/images\"\n",
    "VOLUME_FILES_DIR = \"./DataTrain/labels\"\n",
    "MODEL_SAVE_PATH = \"./mangosteen_volume_model_aug.h5\"\n",
    "SCALER_PATH = \"./volume_scaler.save\"\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_EPOCHS = 200\n",
    "FINE_TUNE_EPOCHS = 0\n",
    "LEARNING_RATE_INITIAL = 1e-3\n",
    "LEARNING_RATE_FINE_TUNE = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f33fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- augmentation helpers ---\n",
    "def random_brightness_contrast(image):\n",
    "    alpha = np.random.uniform(0.8, 1.2)\n",
    "    beta = np.random.uniform(-0.2, 0.2) * 255.0\n",
    "    out = image * alpha + beta\n",
    "    return np.clip(out, 0.0, 255.0)\n",
    "\n",
    "def random_flip_rotate_scale_crop(img):\n",
    "    # flip\n",
    "    if random.random() < 0.5:\n",
    "        img = cv2.flip(img, 1)  # horizontal\n",
    "    # rotate\n",
    "    angle = random.uniform(-15, 15)\n",
    "    M = cv2.getRotationMatrix2D((IMG_SIZE//2, IMG_SIZE//2), angle, 1)\n",
    "    img = cv2.warpAffine(img, M, (IMG_SIZE, IMG_SIZE), borderMode=cv2.BORDER_REFLECT)\n",
    "    # scale\n",
    "    scale = random.uniform(0.9, 1.1)\n",
    "    img = cv2.resize(img, None, fx=scale, fy=scale)\n",
    "    # center crop / resize back\n",
    "    h, w = img.shape[:2]\n",
    "    startx = max(0, w//2 - IMG_SIZE//2)\n",
    "    starty = max(0, h//2 - IMG_SIZE//2)\n",
    "    img = img[starty:starty+IMG_SIZE, startx:startx+IMG_SIZE]\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feccf7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sequence implementation ---\n",
    "class MangosteenSequence(Sequence):\n",
    "    def __init__(self, image_paths, volumes, batch_size, img_size, is_training=True, shuffle=True):\n",
    "        self.image_paths = list(image_paths)\n",
    "        self.volumes = list(volumes)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.is_training = is_training\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.image_paths) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min(start + self.batch_size, len(self.image_paths))\n",
    "        batch_paths = self.image_paths[start:end]\n",
    "        batch_vols = self.volumes[start:end]\n",
    "\n",
    "        images = []\n",
    "        for p in batch_paths:\n",
    "            img = cv2.imread(p)\n",
    "            if img is None:\n",
    "                print(f\"⚠️ Warning: cv2.imread failed for {p}\")\n",
    "                img = np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8)\n",
    "            else:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "            img = img.astype('float32')\n",
    "            if self.is_training:\n",
    "                img = random_brightness_contrast(img)\n",
    "                img = random_flip_rotate_scale_crop(img)\n",
    "            images.append(img)\n",
    "        images = np.stack(images, axis=0) / 255.0\n",
    "        vols = np.array(batch_vols, dtype='float32')\n",
    "        return images, vols\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle and self.is_training:\n",
    "            combined = list(zip(self.image_paths, self.volumes))\n",
    "            random.shuffle(combined)\n",
    "            self.image_paths, self.volumes = zip(*combined)\n",
    "            self.image_paths = list(self.image_paths)\n",
    "            self.volumes = list(self.volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a312da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    }
   ],
   "source": [
    "# --- load data ---\n",
    "def load_data_from_folders(data_dir, volume_dir):\n",
    "    image_paths, volumes = [], []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "            base = filename.split('.',1)[0]\n",
    "            vol_file = os.path.join(volume_dir, base + \".txt\")\n",
    "            if os.path.exists(vol_file):\n",
    "                try:\n",
    "                    with open(vol_file,'r') as f:\n",
    "                        v = float(f.read().strip())\n",
    "                    image_paths.append(os.path.join(data_dir, filename))\n",
    "                    volumes.append(v)\n",
    "                except:\n",
    "                    pass\n",
    "    return image_paths, volumes\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "image_paths, volumes = load_data_from_folders(DATA_DIR, VOLUME_FILES_DIR)\n",
    "if not image_paths:\n",
    "    raise SystemExit(\"❌ No data found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bec9b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./volume_scaler.save']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- normalize volume ---\n",
    "scaler = StandardScaler()\n",
    "volumes_scaled = scaler.fit_transform(np.array(volumes).reshape(-1,1)).flatten()\n",
    "joblib.dump(scaler, SCALER_PATH)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbe3b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- train/val split ---\n",
    "train_paths, val_paths, train_volumes, val_volumes = train_test_split(\n",
    "    image_paths, volumes_scaled, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_seq = MangosteenSequence(train_paths, train_volumes, BATCH_SIZE, IMG_SIZE, is_training=True)\n",
    "val_seq = MangosteenSequence(val_paths, val_volumes, BATCH_SIZE, IMG_SIZE, is_training=False, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54af42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- build model ---\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE,3))\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "predictions = Dense(1, activation='linear')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE_INITIAL),\n",
    "              loss='huber', metrics=['mean_absolute_error'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a958ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training regression head...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\Python\\Project\\Mongoesteen\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 3s/step - loss: 18.9051 - mean_absolute_error: 1.6747 - val_loss: 15.0325 - val_mean_absolute_error: 0.8047 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 12.8050 - mean_absolute_error: 0.7484 - val_loss: 10.4571 - val_mean_absolute_error: 0.6987 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 8.8820 - mean_absolute_error: 0.6187 - val_loss: 7.3436 - val_mean_absolute_error: 0.6602 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 6.3379 - mean_absolute_error: 0.5795 - val_loss: 5.3383 - val_mean_absolute_error: 0.5944 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 4.6940 - mean_absolute_error: 0.5446 - val_loss: 4.0944 - val_mean_absolute_error: 0.5795 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 3.6412 - mean_absolute_error: 0.5111 - val_loss: 3.2264 - val_mean_absolute_error: 0.5594 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 2.9191 - mean_absolute_error: 0.4971 - val_loss: 2.6457 - val_mean_absolute_error: 0.5716 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 2.3713 - mean_absolute_error: 0.4778 - val_loss: 2.1931 - val_mean_absolute_error: 0.5804 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.9741 - mean_absolute_error: 0.4562 - val_loss: 1.8301 - val_mean_absolute_error: 0.5070 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 1.7080 - mean_absolute_error: 0.5036 - val_loss: 1.6331 - val_mean_absolute_error: 0.6367 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 1.4642 - mean_absolute_error: 0.4906 - val_loss: 1.4045 - val_mean_absolute_error: 0.5857 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 1.2808 - mean_absolute_error: 0.4933 - val_loss: 1.2205 - val_mean_absolute_error: 0.5306 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 1.1031 - mean_absolute_error: 0.4402 - val_loss: 1.0678 - val_mean_absolute_error: 0.5115 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - loss: 0.9736 - mean_absolute_error: 0.4457 - val_loss: 0.9777 - val_mean_absolute_error: 0.5695 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.8819 - mean_absolute_error: 0.4586 - val_loss: 0.8737 - val_mean_absolute_error: 0.5297 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 0.7828 - mean_absolute_error: 0.4455 - val_loss: 0.8039 - val_mean_absolute_error: 0.5285 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.7105 - mean_absolute_error: 0.4455 - val_loss: 0.7510 - val_mean_absolute_error: 0.5403 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.6480 - mean_absolute_error: 0.4463 - val_loss: 0.7507 - val_mean_absolute_error: 0.5870 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.5997 - mean_absolute_error: 0.4395 - val_loss: 0.6776 - val_mean_absolute_error: 0.5637 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.5604 - mean_absolute_error: 0.4452 - val_loss: 0.5970 - val_mean_absolute_error: 0.5280 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.5072 - mean_absolute_error: 0.4194 - val_loss: 0.5795 - val_mean_absolute_error: 0.5504 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.4901 - mean_absolute_error: 0.4444 - val_loss: 0.5269 - val_mean_absolute_error: 0.5165 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.4690 - mean_absolute_error: 0.4455 - val_loss: 0.4942 - val_mean_absolute_error: 0.5204 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.4249 - mean_absolute_error: 0.4386 - val_loss: 0.4776 - val_mean_absolute_error: 0.5655 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - loss: 0.4149 - mean_absolute_error: 0.4461 - val_loss: 0.4721 - val_mean_absolute_error: 0.5735 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step - loss: 0.4040 - mean_absolute_error: 0.4522 - val_loss: 0.4265 - val_mean_absolute_error: 0.5129 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.3698 - mean_absolute_error: 0.4357 - val_loss: 0.4135 - val_mean_absolute_error: 0.5163 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.3444 - mean_absolute_error: 0.4250 - val_loss: 0.4125 - val_mean_absolute_error: 0.5319 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.3379 - mean_absolute_error: 0.4261 - val_loss: 0.4022 - val_mean_absolute_error: 0.5266 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.3070 - mean_absolute_error: 0.4048 - val_loss: 0.3739 - val_mean_absolute_error: 0.5088 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2s/step - loss: 0.3302 - mean_absolute_error: 0.4481 - val_loss: 0.3424 - val_mean_absolute_error: 0.4878 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.3024 - mean_absolute_error: 0.4241 - val_loss: 0.3763 - val_mean_absolute_error: 0.5309 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2s/step - loss: 0.3126 - mean_absolute_error: 0.4396 - val_loss: 0.3691 - val_mean_absolute_error: 0.5297 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.2818 - mean_absolute_error: 0.4111 - val_loss: 0.3425 - val_mean_absolute_error: 0.5107 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.2897 - mean_absolute_error: 0.4365 - val_loss: 0.3498 - val_mean_absolute_error: 0.5362 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.3016 - mean_absolute_error: 0.4559 - val_loss: 0.3522 - val_mean_absolute_error: 0.5182 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3s/step - loss: 0.2607 - mean_absolute_error: 0.3983 - val_loss: 0.3531 - val_mean_absolute_error: 0.5627 - learning_rate: 2.0000e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 22s/step - loss: 0.2520 - mean_absolute_error: 0.3948 - val_loss: 0.3329 - val_mean_absolute_error: 0.5156 - learning_rate: 2.0000e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 3s/step - loss: 0.2528 - mean_absolute_error: 0.3944 - val_loss: 0.3291 - val_mean_absolute_error: 0.5143 - learning_rate: 2.0000e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3s/step - loss: 0.2401 - mean_absolute_error: 0.3833 - val_loss: 0.3241 - val_mean_absolute_error: 0.5155 - learning_rate: 2.0000e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - loss: 0.2408 - mean_absolute_error: 0.3820 - val_loss: 0.3267 - val_mean_absolute_error: 0.5324 - learning_rate: 2.0000e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3s/step - loss: 0.2343 - mean_absolute_error: 0.3768 - val_loss: 0.3209 - val_mean_absolute_error: 0.5173 - learning_rate: 2.0000e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.2304 - mean_absolute_error: 0.3763 - val_loss: 0.3271 - val_mean_absolute_error: 0.5261 - learning_rate: 2.0000e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3s/step - loss: 0.2236 - mean_absolute_error: 0.3712 - val_loss: 0.3119 - val_mean_absolute_error: 0.5002 - learning_rate: 2.0000e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4s/step - loss: 0.2158 - mean_absolute_error: 0.3594 - val_loss: 0.3181 - val_mean_absolute_error: 0.5097 - learning_rate: 2.0000e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3s/step - loss: 0.2167 - mean_absolute_error: 0.3538 - val_loss: 0.3098 - val_mean_absolute_error: 0.4988 - learning_rate: 2.0000e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.2260 - mean_absolute_error: 0.3717 - val_loss: 0.3081 - val_mean_absolute_error: 0.4984 - learning_rate: 2.0000e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 3s/step - loss: 0.2019 - mean_absolute_error: 0.3353 - val_loss: 0.3210 - val_mean_absolute_error: 0.5378 - learning_rate: 2.0000e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - loss: 0.2223 - mean_absolute_error: 0.3769 - val_loss: 0.3099 - val_mean_absolute_error: 0.5024 - learning_rate: 2.0000e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.2053 - mean_absolute_error: 0.3489 - val_loss: 0.3093 - val_mean_absolute_error: 0.5267 - learning_rate: 2.0000e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - loss: 0.2030 - mean_absolute_error: 0.3453 - val_loss: 0.2923 - val_mean_absolute_error: 0.4900 - learning_rate: 2.0000e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3s/step - loss: 0.2157 - mean_absolute_error: 0.3591 - val_loss: 0.3016 - val_mean_absolute_error: 0.5179 - learning_rate: 2.0000e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - loss: 0.2159 - mean_absolute_error: 0.3783 - val_loss: 0.2893 - val_mean_absolute_error: 0.4931 - learning_rate: 2.0000e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.2081 - mean_absolute_error: 0.3661 - val_loss: 0.2966 - val_mean_absolute_error: 0.5070 - learning_rate: 2.0000e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3s/step - loss: 0.1996 - mean_absolute_error: 0.3509 - val_loss: 0.2900 - val_mean_absolute_error: 0.4971 - learning_rate: 2.0000e-04\n",
      "Epoch 56/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step - loss: 0.2095 - mean_absolute_error: 0.3664 - val_loss: 0.2914 - val_mean_absolute_error: 0.4952 - learning_rate: 2.0000e-04\n",
      "Epoch 57/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3s/step - loss: 0.1970 - mean_absolute_error: 0.3605 - val_loss: 0.2914 - val_mean_absolute_error: 0.5103 - learning_rate: 2.0000e-04\n",
      "Epoch 58/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3s/step - loss: 0.1913 - mean_absolute_error: 0.3410 - val_loss: 0.3039 - val_mean_absolute_error: 0.5258 - learning_rate: 2.0000e-04\n",
      "Epoch 59/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.1915 - mean_absolute_error: 0.3483 - val_loss: 0.2990 - val_mean_absolute_error: 0.5127 - learning_rate: 4.0000e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 3s/step - loss: 0.1907 - mean_absolute_error: 0.3413 - val_loss: 0.2931 - val_mean_absolute_error: 0.5026 - learning_rate: 4.0000e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 3s/step - loss: 0.1950 - mean_absolute_error: 0.3490 - val_loss: 0.2905 - val_mean_absolute_error: 0.4998 - learning_rate: 4.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 3s/step - loss: 0.1954 - mean_absolute_error: 0.3494 - val_loss: 0.2947 - val_mean_absolute_error: 0.5099 - learning_rate: 4.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3s/step - loss: 0.1872 - mean_absolute_error: 0.3399 - val_loss: 0.2944 - val_mean_absolute_error: 0.5030 - learning_rate: 4.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23697b32250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- train regression head ---\n",
    "print(\"Training regression head...\")\n",
    "model.fit(train_seq, validation_data=val_seq, epochs=INITIAL_EPOCHS, callbacks=callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3988dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning base model (last block)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x236acfcfb50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- fine-tune last block only ---\n",
    "for layer in base_model.layers:\n",
    "    if 'block14' in layer.name:  # ปลดล็อกเฉพาะ block14\n",
    "        layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE_FINE_TUNE),\n",
    "              loss='huber', metrics=['mean_absolute_error'])\n",
    "\n",
    "print(\"Fine-tuning base model (last block)...\")\n",
    "model.fit(train_seq, validation_data=val_seq, epochs=FINE_TUNE_EPOCHS, callbacks=callbacks, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08056db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to ./mangosteen_volume_model_aug.h5\n"
     ]
    }
   ],
   "source": [
    "# --- save model ---\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(f\"✅ Model saved to {MODEL_SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
