{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "850603ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1aabc45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b273d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "876939e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a07a9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- config (ใช้ค่าของคุณ) ---\n",
    "DATA_DIR = \"./DataTrain/image\"\n",
    "VOLUME_FILES_DIR = \"./DataTrain/label\"\n",
    "MODEL_SAVE_PATH = \"./mangosteen_volume_model_all.h5\"\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "INITIAL_EPOCHS = 30\n",
    "FINE_TUNE_EPOCHS = 20\n",
    "LEARNING_RATE_INITIAL = 1e-3\n",
    "LEARNING_RATE_FINE_TUNE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01990112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helper augmentation (numpy-based, per-image) ---\n",
    "def random_brightness_contrast(image):\n",
    "    \"\"\"\n",
    "    image: float32, range 0..255\n",
    "    contrast alpha ~ U(0.8,1.2)\n",
    "    brightness beta ~ U(-0.2*255, 0.2*255)\n",
    "    \"\"\"\n",
    "    alpha = np.random.uniform(0.8, 1.2)\n",
    "    beta = np.random.uniform(-0.2, 0.2) * 255.0\n",
    "    out = image * alpha + beta\n",
    "    out = np.clip(out, 0.0, 255.0)\n",
    "    return out\n",
    "\n",
    "# --- Sequence implementation (stable for Keras) ---\n",
    "class MangosteenSequence(Sequence):\n",
    "    def __init__(self, image_paths, volumes, batch_size, img_size, is_training=True, shuffle=True):\n",
    "        self.image_paths = list(image_paths)\n",
    "        self.volumes = list(volumes)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.is_training = is_training\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # return number of batches per epoch (ceil ensures we include last partial batch)\n",
    "        return math.ceil(len(self.image_paths) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.batch_size\n",
    "        end = min(start + self.batch_size, len(self.image_paths))\n",
    "        batch_paths = self.image_paths[start:end]\n",
    "        batch_vols = self.volumes[start:end]\n",
    "\n",
    "        images = []\n",
    "        for p in batch_paths:\n",
    "            img = cv2.imread(p)\n",
    "            if img is None:\n",
    "                # If an image fails to load, replace with zeros and warn\n",
    "                print(f\"⚠️ Warning: cv2.imread failed for {p}\")\n",
    "                img = np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8)\n",
    "            else:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                img = cv2.resize(img, (self.img_size, self.img_size))\n",
    "            img = img.astype('float32')\n",
    "            if self.is_training:\n",
    "                # per-image augmentation\n",
    "                img = random_brightness_contrast(img)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.stack(images, axis=0) / 255.0  # normalize to 0..1\n",
    "        vols = np.array(batch_vols, dtype='float32')\n",
    "        return images, vols\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle and self.is_training:\n",
    "            combined = list(zip(self.image_paths, self.volumes))\n",
    "            random.shuffle(combined)\n",
    "            self.image_paths, self.volumes = zip(*combined)\n",
    "            self.image_paths = list(self.image_paths)\n",
    "            self.volumes = list(self.volumes)\n",
    "\n",
    "\n",
    "# --- load data (reuse your function or keep current) ---\n",
    "def load_data_from_folders(data_dir, volume_dir):\n",
    "    image_paths = []\n",
    "    volumes = []\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"❌ Image data directory not found: {data_dir}\")\n",
    "        return [], []\n",
    "    if not os.path.exists(volume_dir):\n",
    "        print(f\"❌ Volume data directory not found: {volume_dir}\")\n",
    "        return [], []\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            base = filename.split('.', 1)[0]\n",
    "            vol_file = os.path.join(volume_dir, base + \".txt\")\n",
    "            if os.path.exists(vol_file):\n",
    "                try:\n",
    "                    with open(vol_file,'r') as f:\n",
    "                        v = float(f.read().strip())\n",
    "                    image_paths.append(os.path.join(data_dir, filename))\n",
    "                    volumes.append(v)\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Skipping {filename}: {e}\")\n",
    "            else:\n",
    "                print(f\"⚠️ No matching volume file for {filename}\")\n",
    "    return image_paths, volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c1b8a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Total samples: 235, train: 188, val: 47\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data...\")\n",
    "image_paths, volumes = load_data_from_folders(DATA_DIR, VOLUME_FILES_DIR)\n",
    "if not image_paths:\n",
    "    raise SystemExit(\"❌ No matching image and volume data found. Please check your paths and filenames.\")\n",
    "\n",
    "train_paths, val_paths, train_volumes, val_volumes = train_test_split(\n",
    "    image_paths, volumes, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(image_paths)}, train: {len(train_paths)}, val: {len(val_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f1cf8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches per epoch (train): 6  (val): 2\n",
      "Sample batch shape: (32, 224, 224, 3) (32,)\n"
     ]
    }
   ],
   "source": [
    "# --- create sequences ---\n",
    "train_seq = MangosteenSequence(train_paths, train_volumes, BATCH_SIZE, IMG_SIZE, is_training=True)\n",
    "val_seq = MangosteenSequence(val_paths, val_volumes, BATCH_SIZE, IMG_SIZE, is_training=False, shuffle=False)\n",
    "\n",
    "# quick debug print\n",
    "print(\"Batches per epoch (train):\", len(train_seq), \" (val):\", len(val_seq))\n",
    "x0, y0 = train_seq[0]\n",
    "print(\"Sample batch shape:\", x0.shape, y0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0191b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building model...\n"
     ]
    }
   ],
   "source": [
    "# --- model build (reuse your architecture) ---\n",
    "print(\"\\nBuilding model...\")\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "predictions = Dense(1, activation='linear')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=LEARNING_RATE_INITIAL), loss='mean_squared_error', metrics=['mean_absolute_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fa67d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- callbacks ---\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0d8a911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the regression head...\n",
      "Epoch 1/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4s/step - loss: 1849.5120 - mean_absolute_error: 35.9131 - val_loss: 1268.9559 - val_mean_absolute_error: 31.1261 - learning_rate: 0.0010\n",
      "Epoch 2/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 838.1856 - mean_absolute_error: 22.9715 - val_loss: 499.7124 - val_mean_absolute_error: 17.3887 - learning_rate: 0.0010\n",
      "Epoch 3/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - loss: 574.8273 - mean_absolute_error: 16.7079 - val_loss: 211.1373 - val_mean_absolute_error: 10.9952 - learning_rate: 0.0010\n",
      "Epoch 4/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 478.3894 - mean_absolute_error: 17.3402 - val_loss: 223.6968 - val_mean_absolute_error: 11.3985 - learning_rate: 0.0010\n",
      "Epoch 5/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 398.8846 - mean_absolute_error: 14.1316 - val_loss: 292.7765 - val_mean_absolute_error: 12.4476 - learning_rate: 0.0010\n",
      "Epoch 6/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 368.5177 - mean_absolute_error: 13.8370 - val_loss: 252.2896 - val_mean_absolute_error: 12.3273 - learning_rate: 0.0010\n",
      "Epoch 7/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - loss: 349.2381 - mean_absolute_error: 14.2105 - val_loss: 245.8269 - val_mean_absolute_error: 11.0350 - learning_rate: 0.0010\n",
      "Epoch 8/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - loss: 327.7874 - mean_absolute_error: 12.6426 - val_loss: 217.4434 - val_mean_absolute_error: 10.9765 - learning_rate: 0.0010\n",
      "Epoch 9/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - loss: 317.0088 - mean_absolute_error: 13.6446 - val_loss: 218.1108 - val_mean_absolute_error: 11.0348 - learning_rate: 2.0000e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 331.1033 - mean_absolute_error: 13.3046 - val_loss: 216.5345 - val_mean_absolute_error: 10.4216 - learning_rate: 2.0000e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - loss: 304.5576 - mean_absolute_error: 12.6590 - val_loss: 220.7848 - val_mean_absolute_error: 10.3592 - learning_rate: 2.0000e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - loss: 292.7042 - mean_absolute_error: 12.0944 - val_loss: 217.3905 - val_mean_absolute_error: 10.3838 - learning_rate: 2.0000e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - loss: 287.5066 - mean_absolute_error: 12.2456 - val_loss: 214.5566 - val_mean_absolute_error: 10.5575 - learning_rate: 2.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c0a8bdcd90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- fit (use Sequence, no manual steps_per_epoch) ---\n",
    "print(\"Training the regression head...\")\n",
    "model.fit(\n",
    "    train_seq,\n",
    "    validation_data=val_seq,\n",
    "    epochs=INITIAL_EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b9c6f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning the model (unfreeze last blocks)...\n",
      "Epoch 1/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - loss: 374.4413 - mean_absolute_error: 14.4978 - val_loss: 210.9432 - val_mean_absolute_error: 10.9841 - learning_rate: 4.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 367.8642 - mean_absolute_error: 14.2360 - val_loss: 210.7552 - val_mean_absolute_error: 10.9263 - learning_rate: 4.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 383.7061 - mean_absolute_error: 14.4072 - val_loss: 210.8461 - val_mean_absolute_error: 10.8539 - learning_rate: 4.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 373.4936 - mean_absolute_error: 14.0215 - val_loss: 211.4458 - val_mean_absolute_error: 10.7969 - learning_rate: 4.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 381.2910 - mean_absolute_error: 14.1650 - val_loss: 211.4505 - val_mean_absolute_error: 10.7736 - learning_rate: 4.0000e-05\n",
      "Epoch 6/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 378.8462 - mean_absolute_error: 14.3515 - val_loss: 211.2191 - val_mean_absolute_error: 10.7570 - learning_rate: 4.0000e-05\n",
      "Epoch 7/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 365.6109 - mean_absolute_error: 14.1323 - val_loss: 211.0428 - val_mean_absolute_error: 10.7443 - learning_rate: 4.0000e-05\n",
      "Epoch 8/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 371.5822 - mean_absolute_error: 14.0958 - val_loss: 210.9450 - val_mean_absolute_error: 10.7430 - learning_rate: 8.0000e-06\n",
      "Epoch 9/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 365.4456 - mean_absolute_error: 13.6403 - val_loss: 210.8648 - val_mean_absolute_error: 10.7411 - learning_rate: 8.0000e-06\n",
      "Epoch 10/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 360.5700 - mean_absolute_error: 13.8624 - val_loss: 210.8353 - val_mean_absolute_error: 10.7386 - learning_rate: 8.0000e-06\n",
      "Epoch 11/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 356.0251 - mean_absolute_error: 13.5600 - val_loss: 210.7940 - val_mean_absolute_error: 10.7368 - learning_rate: 8.0000e-06\n",
      "Epoch 12/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - loss: 371.3311 - mean_absolute_error: 14.1478 - val_loss: 210.8843 - val_mean_absolute_error: 10.7320 - learning_rate: 8.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model to ./mangosteen_volume_model_all.h5\n",
      "✅ Model saved.\n"
     ]
    }
   ],
   "source": [
    "# --- fine-tune ---\n",
    "print(\"\\nFine-tuning the model (unfreeze last blocks)...\")\n",
    "# (หลังจาก unfreeze และ compile แล้ว)\n",
    "model.fit(\n",
    "    train_seq,\n",
    "    validation_data=val_seq,\n",
    "    epochs=FINE_TUNE_EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nSaving model to {MODEL_SAVE_PATH}\")\n",
    "model.save(MODEL_SAVE_PATH)\n",
    "print(\"✅ Model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
